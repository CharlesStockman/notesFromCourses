{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c09fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf  version =  2.8.0\n",
      "tfp version =  0.16.0\n",
      "np  version =  1.22.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "print(\"tf  version = \", tf.__version__)\n",
    "print(\"tfp version = \", tfp.__version__)\n",
    "print(\"np  version = \", np.__version__)\n",
    "separator=\"================\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0eb61",
   "metadata": {},
   "source": [
    "\n",
    "# Notes \n",
    "In practice you rarely need to decide to use a constant/varialbe tensor to crearte tensors.  However, if the oppurtunity arises then use the create a constnat tensor first and chang to a variable if need\n",
    "\n",
    "Uniform Distribution has Constant Probability.  All the outcomes have the same probability\n",
    "\n",
    "Normal Distribution -- A function that represents the distribution of many random variables as a symmetrical bell shaped graph.\n",
    "\n",
    "The ndim is 0 for a constant, 1 for a scalar, 2 for a matrix and the last dimnesion for a tensor.\n",
    "for ndim is the first number of the shape.\n",
    "\n",
    "## What is a tensor\n",
    "An array with a uniform type which is immutable that can be used on GPU(s) and TPU\n",
    "\n",
    "### Other Types of Tensors \n",
    "    Ragged Tensors -- A tensor with a vrialbe number of elements along some axis.  Used for   \n",
    "    varible length features (actors in movies, hierachical inputs such as text documents ( \n",
    "    divided into sections, paragraphs and sentences) or Individual fields in structured inputs\n",
    "    (such as protocol buffers \n",
    "    \n",
    "    Sparse Tensors -- Used when your data space contains very little data\n",
    "    \n",
    "### Internals\n",
    "When a tensor is reshaped in memory and a new tensor is created with the request shape, point to the same data tensorFlow use C-Style Row Major memeory order where incrementing the rightmost index corect to a single step in memory.\n",
    "\n",
    "In order to see how it layed out of memory tf.reshape(rank_3_tensor, [-1]))\n",
    "\n",
    "#### Knowledge I cannot find any where else ot put\n",
    "\n",
    "Reasonable reuses of reshape --> Combine or split adjacent axes ( add/remove 1s).  Try to not reshape the tensor such that the data is not contained in the same 2D part of the shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72f8e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar constant =  tf.Tensor(7, shape=(), dtype=int32)\n",
      "scalar variable =  <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>\n",
      "scalar constant number of dimensions =  0\n"
     ]
    }
   ],
   "source": [
    "# create constant\n",
    "# That a scalar ( rank 0 ) has no shape\n",
    "scalarConstant = tf.constant(7)\n",
    "scalarVariable = tf.Variable(7)\n",
    "\n",
    "print(\"scalar constant = \", scalarConstant)\n",
    "print(\"scalar variable = \", scalarVariable)\n",
    "print(\"scalar constant number of dimensions = \", scalarConstant.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d403a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector constant =  tf.Tensor([10 10], shape=(2,), dtype=int32)\n",
      "Vector variable =  <tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10, 10], dtype=int32)>\n",
      "vector constant number of dimensions =  1\n"
     ]
    }
   ],
   "source": [
    "# create vectors - A number with direction\n",
    "vectorConstant = tf.constant([10,10])\n",
    "vectorVariable = tf.Variable([10,10])\n",
    "print(\"vector constant = \", vectorConstant)\n",
    "print(\"Vector variable = \", vectorVariable)\n",
    "print(\"vector constant number of dimensions = \", vectorConstant.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb2a70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix constant = \n",
      " tf.Tensor(\n",
      "[[ 7 10]\n",
      " [10  7]], shape=(2, 2), dtype=int32)\n",
      "matrix variable = \n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[ 7, 10],\n",
      "       [10,  7]], dtype=int32)>\n",
      "matrix constant number of dimensions =  2\n"
     ]
    }
   ],
   "source": [
    "# create matrix\n",
    "matrixConstant = tf.constant([ [7,10], [10,7]])\n",
    "matrixVariable = tf.Variable([ [7,10], [10,7]])\n",
    "print(\"matrix constant = \\n\", matrixConstant)\n",
    "print(\"matrix variable = \\n\", matrixVariable)\n",
    "print(\"matrix constant number of dimensions = \", matrixConstant.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "434a78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix constant show use of dtype =  tf.Tensor(\n",
      "[[10.  7.]\n",
      " [ 7. 10.]], shape=(2, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Use the dtype when using the msrtrix to provide the correct datatype to the matrix.\n",
    "# don't leave it up to the data.\n",
    "# A period after the number means it is a float which default is float32\n",
    "# The higher the precision the more accurate the numbers are.\n",
    "# Use : when you get the wrong datatype use dtype to make it the correct one.\n",
    "\n",
    "another_matrix = tf.constant( [ [10.,7.], [7.,10.]] , dtype=tf.float16)\n",
    "print(\"matrix constant show use of dtype = \", another_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f03bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor constant = \n",
      " tf.Tensor(\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]\n",
      "\n",
      " [[13 14 15]\n",
      "  [16 17 18]]], shape=(3, 2, 3), dtype=int32)\n",
      "================\n",
      "tensor variable = \n",
      " <tf.Variable 'Variable:0' shape=(3, 2, 3) dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3],\n",
      "        [ 4,  5,  6]],\n",
      "\n",
      "       [[ 7,  8,  9],\n",
      "        [10, 11, 12]],\n",
      "\n",
      "       [[13, 14, 15],\n",
      "        [16, 17, 18]]], dtype=int32)>\n",
      "tensor number of dimensions  3\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor -- An n-dimensional array of numbers\n",
    "tensorConstant = tf.constant(\n",
    "    [ [[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]], [[13,14,15], [16,17,18]] ])\n",
    "tensorVariable = tf.Variable(\n",
    "     [ [[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]], [[13,14,15], [16,17,18]] ])\n",
    "print(\"tensor constant = \\n\", tensorConstant)\n",
    "print(separator)\n",
    "print(\"tensor variable = \\n\", tensorVariable)\n",
    "print(\"tensor number of dimensions \", tensorConstant.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5267133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Vector Variable  <tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10, 10], dtype=int32)>\n",
      "Changed the vector using assign --  <tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([ 2, 10], dtype=int32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2,) dtype=int32, numpy=array([12, 20], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value one element in a vector\n",
    "print(\"Original Vector Variable \", vectorVariable)\n",
    "vectorVariable[0].assign((2))\n",
    "print(\"Changed the vector using assign -- \",vectorVariable)\n",
    "vectorVariable.assign_add([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "497fc64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.23193763, -1.8107855 ],\n",
       "        [ 0.09988727, -0.50998646],\n",
       "        [-0.7535805 , -0.57166284]], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensor\n",
    "# Create Random Tensors for the initial weights of the hidden layers\n",
    "random_1 = tf.random.Generator.from_seed(42)\n",
    "random_1 = random_1.normal(shape=(3,2))\n",
    "random_2 = tf.random.Generator.from_seed(43)\n",
    "random_2 = random_2.normal(shape=(3,2))\n",
    "\n",
    "random_1, separator, random_2, separator, random_1 == random_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00e049a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4],\n",
       "        [ 2,  5]], dtype=int32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 2,  5],\n",
       "        [10,  7],\n",
       "        [ 3,  4]], dtype=int32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4],\n",
       "        [ 2,  5]], dtype=int32)>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the order of tensors \n",
    "# Shuffle data so the inherent order does not affect learning \n",
    "#    Ex.  Too many of the same image type ( ex. dog ) it might be able to learn cats.\n",
    "# Shuffle_1 -- Shuffles the rows the columns stay the same\n",
    "# Shuffle_2 -- Same as shuffle_1, but event with the parameter seed set we get different results\n",
    "not_shuffled = tf.constant( [ [10,7], [3,4], [2,5] ] )\n",
    "shuffled_1 = tf.random.shuffle(not_shuffled )\n",
    "shuffled_2 = tf.random.shuffle(not_shuffled, seed=42)\n",
    "not_shuffled, separator, shuffled_1, separator, shuffled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23fcaab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 2,  5],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how use the seed to produce a shuffle thatd does not change with each prefix\n",
    "# If both global and operations seeds are set: Both seeds are used in conjuction to determine the randome sequence.\n",
    "tf.random.set_seed(43)\n",
    "tf.random.shuffle(not_shuffled, seed = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "005ee784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24], dtype=int32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]]], dtype=int32)>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Other Ways to make tensors\n",
    "#The main difference between numpy arrays and TensorFlow is that tensors can be run on a GPU.\n",
    "#Changing the shape the total number of elements must be the same for both shapes\n",
    "other_way_1 = tf.ones(shape=(3,3))\n",
    "other_way_2 = tf.zeros(shape=(3,3))\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32)\n",
    "\n",
    "#Turn Numpy Arrays into tensors\n",
    "other_way_3 = tf.constant(numpy_A)\n",
    "other_way_3_new_shape = tf.constant(numpy_A, shape=(2,3,4))\n",
    "\n",
    "\n",
    "other_way_1, separator, other_way_2, separator, other_way_3, separator, other_way_3_new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24529c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]], dtype=float32)>,\n",
       " '================',\n",
       " 4,\n",
       " '================',\n",
       " TensorShape([2, 3, 4, 5]),\n",
       " '================',\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=120>,\n",
       " '================',\n",
       " 'Use numpy to get the number\\n',\n",
       " 120)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting information from your tensor ( tensor attributes )\n",
    "# Shape -- The length of each of the dimensions of a tensor\n",
    "#     Always start with the out \"[\"\n",
    "# Rank -- The number of tensor dimensions \n",
    "#   ( scalar = rank 0, vector = rank 1, matrix =  rank 2, tensor = rank n)\n",
    "# Axis or dimension -- The specific dimension of a tensor ( indexing the [] operator)\n",
    "# size -- The total number of items in a dimension\n",
    "# .numpy -- Provides the value\n",
    "\n",
    "# Axes are ordered from global to local. \n",
    "#    The batch axis is followed by the spatial dimensions and features for each location last.\n",
    "#    Example A Shape of ( 3,2,4,5) has batch =3, width = 2, height=4, features=5\n",
    "# About 9:27 -- A script for pretty print a tensor\n",
    "\n",
    "# create a rank 4 dimension\n",
    "rank_4_tensor = tf.zeros(shape=(2,3,4,5))\n",
    "\n",
    "rank_4_tensor, separator, rank_4_tensor.ndim, separator, rank_4_tensor.shape, separator, tf.size(rank_4_tensor), separator, \"Use numpy to get the number\\n\", tf.size(rank_4_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e62d9893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the first 2 element of each dimension tf.Tensor(\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]], shape=(2, 2, 2, 2), dtype=float32)\n",
      "================\n",
      "Get the first element from each dimension from each index except the final one tf.Tensor([[[[0. 0. 0. 0. 0.]]]], shape=(1, 1, 1, 5), dtype=float32)\n",
      "================\n",
      "Get the first element from each dimension from each index accept the previous to the last tf.Tensor(\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]], shape=(1, 1, 4, 1), dtype=float32)\n",
      "================\n",
      "Maxtrix before reversing  tf.Tensor(\n",
      "[[10  7]\n",
      " [ 7  4]], shape=(2, 2), dtype=int32)\n",
      "Reverse the maxtrix  tf.Tensor(\n",
      "[[ 7  4]\n",
      " [10  7]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Get the last item of each row of rank 2 -  tf.Tensor([7 4], shape=(2,), dtype=int32)\n",
      "Add an extra dimensions  tf.Tensor(\n",
      "[[[10]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 7]\n",
      "  [ 4]]], shape=(2, 2, 1), dtype=int32)  and the shape is  (2, 2, 1)\n",
      "Add an extra dimensions  tf.Tensor(\n",
      "[[[10]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 7]\n",
      "  [ 4]]], shape=(2, 2, 1), dtype=int32)  and the shape is  (2, 2, 1)\n",
      "Add an extra dimensions  tf.Tensor(\n",
      "[[[10  7]\n",
      "  [ 7  4]]], shape=(1, 2, 2), dtype=int32)  and the shape is  (1, 2, 2)\n",
      "Add an extra dimensions  tf.Tensor(\n",
      "[[[10  7]]\n",
      "\n",
      " [[ 7  4]]], shape=(2, 1, 2), dtype=int32)  and the shape is  (2, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Indexing and Expanding\n",
    "# Tensors can be indexed just like Tensor List\n",
    "# When using -1 as a step it reverses all dimensins\n",
    "# ... means all every axis prior to.\n",
    "# A single colon in slicing means get the whole dimension\n",
    "rank_2_tensor = tf.constant( [ [10,7], [7,4] ])\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
    "rank_3a_tensor = tf.expand_dims(rank_2_tensor, axis=-1)  # put on end \n",
    "rank_3b_tensor = tf.expand_dims(rank_2_tensor, axis=0)   # put on beginning\n",
    "rank_3c_tensor = tf.expand_dims(rank_2_tensor, axis=1)\n",
    "\n",
    "\n",
    "# Get the first 2 element of each dimension\n",
    "# Get the first element from each dimension from each index except the final one\n",
    "# Get the first element from each dimension from each index accept the previous to the last\n",
    "print(\"Get the first 2 element of each dimension\", rank_4_tensor[:2,:2,:2,:2])\n",
    "print(separator)\n",
    "print(\"Get the first element from each dimension from each index except the final one\", rank_4_tensor[:1,:1,:1])\n",
    "print (separator)\n",
    "print(\"Get the first element from each dimension from each index accept the previous to the last\", rank_4_tensor[:1,:1,:,:1])\n",
    "print(separator)\n",
    "print(\"Maxtrix before reversing \", rank_2_tensor)\n",
    "print(\"Reverse the maxtrix \", rank_2_tensor[::-1])\n",
    "print(separator)\n",
    "print(\"Get the last item of each row of rank 2 - \", rank_2_tensor[:,-1])\n",
    "print(\"Add an extra dimensions \", rank_3_tensor, \" and the shape is \", rank_3_tensor.shape)\n",
    "print(\"Add an extra dimensions \", rank_3a_tensor, \" and the shape is \", rank_3a_tensor.shape)\n",
    "print(\"Add an extra dimensions \", rank_3b_tensor, \" and the shape is \", rank_3b_tensor.shape)\n",
    "print(\"Add an extra dimensions \", rank_3c_tensor, \" and the shape is \", rank_3c_tensor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bc98be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition tf.Tensor(\n",
      "[[20 17]\n",
      " [13 14]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Multiplication =  tf.Tensor(\n",
      "[[100  70]\n",
      " [ 30  40]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Subtraction =  tf.Tensor(\n",
      "[[ 5  2]\n",
      " [-2 -1]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Multiplication 2 =  tf.Tensor(\n",
      "[[121  98]\n",
      " [ 42  37]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Manipualting Tensors with basic Operations\n",
    "# For tf.math.multiply can be tf.multiply\n",
    "# Use tf.math to get the speed of tensors vs python list\n",
    "# Home work compare the speed of * on tensors vs tf.math.multiply\n",
    "# elementwise -- Go through each element and perfrom the operation\n",
    "tensor = tf.constant( [ [10,7], [3,4] ])\n",
    "print(\"Addition\", tensor + 10)\n",
    "print(separator)\n",
    "print(\"Multiplication = \", tensor * 10)\n",
    "print(separator)\n",
    "print(\"Subtraction = \", tensor - 5)\n",
    "print(separator)\n",
    "print(\"Multiplication 2 = \", tensor @ tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "699845d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor =  tf.Tensor(\n",
      "[[10  7]\n",
      " [ 7  4]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Matrix Multiplication =  tf.Tensor(\n",
      "[[149  98]\n",
      " [ 98  65]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Matrix =  tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [7 9]], shape=(3, 2), dtype=int32)\n",
      "================\n",
      "Matrix Multiplication Transpose =  tf.Tensor(\n",
      "[[ 59  77]\n",
      " [ 77 101]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Matrix Multiplication reshape =  tf.Tensor(\n",
      "[[ 28  37]\n",
      " [ 88 117]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Dot Product Transpose =  tf.Tensor(\n",
      "[[ 59  77]\n",
      " [ 77 101]], shape=(2, 2), dtype=int32)\n",
      "================\n",
      "Dot Product reshape =  tf.Tensor(\n",
      "[[ 28  37]\n",
      " [ 88 117]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix Mulitplication\n",
    "# In machine learning marix multipliations are the most common operation\n",
    "# Dot Product is matrix multipliation and @ is the ptython operator \n",
    "# Use tf.linalg.matmul -- linear algerbra or tf.tensordot()\n",
    "# Rules : \n",
    "# The inner dimensions must match \n",
    "# The resulting matrix has the shape of the outer dimensions\n",
    "# Which ones should I use -- maxtrix multiplication is usually \n",
    "#   If the shapes don't match then transpose the tensors rather than reshaping them. \n",
    "#   reshaping is just shulffing the rows around.\n",
    "\n",
    "tensor2 = tf.constant( [ [1,2], [3,4], [5,6] ])\n",
    "tensor3 = tf.constant( [ [1,2], [3,4], [7,9] ])\n",
    "\n",
    "print(\"Original Tensor = \", rank_2_tensor)\n",
    "print(separator)\n",
    "print(\"Matrix Multiplication = \", tf.linalg.matmul(rank_2_tensor, rank_2_tensor))\n",
    "print(separator)\n",
    "print(\"Matrix = \", tensor3)\n",
    "print(separator)\n",
    "print(\"Matrix Multiplication Transpose = \", tf.linalg.matmul(tf.transpose(tensor3), tensor3))\n",
    "print(separator)\n",
    "print(\"Matrix Multiplication reshape = \", tf.linalg.matmul(tf.reshape(tensor3, shape=(2,3)), tensor3))\n",
    "print(separator)\n",
    "print(\"Dot Product Transpose = \", tf.linalg.tensordot(tf.transpose(tensor3), tensor3, axes=1))\n",
    "print(separator)\n",
    "print(\"Dot Product reshape = \", tf.linalg.tensordot(tf.reshape(tensor3, shape=(2,3)), tensor3, axes=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35ba2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix used for this exercise tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [7. 9.]], shape=(3, 2), dtype=float32)\n",
      "================\n",
      "The data type is  <dtype: 'float32'>\n",
      "================\n",
      "Change the datatype -  tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [7. 9.]], shape=(3, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Changing the datatype of tensors\n",
    "# The default is int32 \n",
    "# For floats we can use foat 32bit precsion, but we can do float 16 ( Modern accelerators ( CPU, TPU) can run faster)\n",
    "\n",
    "tensor4 = tf.constant( [ [1.,2], [3,4], [7,9] ])\n",
    "\n",
    "print(\"The matrix used for this exercise\", tensor4)\n",
    "print(separator)\n",
    "print(\"The data type is \", tensor4.dtype)\n",
    "print(separator)\n",
    "print (\"Change the datatype - \", tf.cast(tensor4, dtype=tf.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "020bf54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor used in this exercise =  tf.Tensor([ -7 -10], shape=(2,), dtype=int32)\n",
      "================\n",
      "The Absolute value of the Tensor =  tf.Tensor([ 7 10], shape=(2,), dtype=int32)\n",
      "================\n",
      "The mininium of the tensor is  tf.Tensor(-10, shape=(), dtype=int32)\n",
      "================\n",
      "The maximum of the tensor is  tf.Tensor(-7, shape=(), dtype=int32)\n",
      "================\n",
      "The mean of the tensor is  tf.Tensor(-8, shape=(), dtype=int32)\n",
      "================\n",
      "The sum of the tensor is  tf.Tensor(-17, shape=(), dtype=int32)\n",
      "================\n",
      "The variance of the tensor is  tf.Tensor(2.25, shape=(), dtype=float16)\n",
      "================\n",
      "The Standard Devication of the tensor is  tf.Tensor(1.5, shape=(), dtype=float16)\n",
      "================\n",
      "The variance of the tensor is  tf.Tensor(2.25, shape=(), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Tensor Aggregation ( finding the min, max, mean and more )\n",
    "# Aggregation condensing a collection of data few values, mainly one value\n",
    "# float 32 is the standard type throught out the library\n",
    "tensor5 = tf.constant( [-7, -10])\n",
    "print(\"The tensor used in this exercise = \", tensor5)\n",
    "print(separator)\n",
    "print(\"The Absolute value of the Tensor = \", tf.abs(tensor5))\n",
    "print(separator)\n",
    "print(\"The mininium of the tensor is \", tf.reduce_min(tensor5))\n",
    "print(separator)\n",
    "print(\"The maximum of the tensor is \", tf.reduce_max(tensor5))\n",
    "print(separator)\n",
    "print(\"The mean of the tensor is \", tf.reduce_mean(tensor5))\n",
    "print(separator)\n",
    "print(\"The sum of the tensor is \", tf.reduce_sum(tensor5))\n",
    "print(separator)\n",
    "print(\"The variance of the tensor is \", tfp.stats.variance(tf.cast(tensor5, tf.float16)))\n",
    "print(separator)\n",
    "print(\"The Standard Devication of the tensor is \", tfp.stats.stddev(tf.cast(tensor5, tf.float16)))\n",
    "print(separator)\n",
    "print(\"The variance of the tensor is \", tf.math.reduce_variance(tf.cast(tensor5, tf.float16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64533640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       " array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "        0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "        0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "        0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "        0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "        0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "        0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "        0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "        0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "        0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "       dtype=float32)>,\n",
       " '================',\n",
       " ('max index of  tensor =', 'tf.Tensor(42, shape=(), dtype=int64)'),\n",
       " ('max value of tensor = ', 'tf.Tensor(0.9671384, shape=(), dtype=float32)'),\n",
       " ('Using reduce_max = ', 'tf.Tensor(0.9671384, shape=(), dtype=float32)'),\n",
       " '================',\n",
       " <tf.Tensor: shape=(), dtype=bool, numpy=True>,\n",
       " '================',\n",
       " ('min index of tensor = ', 'tf.Tensor(16, shape=(), dtype=int64)'),\n",
       " ('min value of tensor = ', 'tf.Tensor(0.009463668, shape=(), dtype=float32)'),\n",
       " ('min value using reduce_min = ',\n",
       "  'tf.Tensor(0.009463668, shape=(), dtype=float32)'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the positinoal minimum and maximum\n",
    "# When neural network predication probabilities find the highest number in the matrix ( by column )\n",
    "# using the set_seed got the same values as the instructor\n",
    "tf.random.set_seed(42)\n",
    "tensor6 = tf.random.uniform(shape=[50])\n",
    "maxIndex = tf.argmax(tensor6)\n",
    "maxIndexStr = \"max index of  tensor =\", str(maxIndex)\n",
    "max_value1 = tensor6[maxIndex]\n",
    "maxValue1Str = \"max value of tensor = \", str(max_value1)\n",
    "max_value2 = tf.reduce_max(tensor6)\n",
    "maxValueStr2 = \"Using reduce_max = \", str(max_value2)\n",
    "minIndex = tf.argmin(tensor6)\n",
    "minIndexStr = \"min index of tensor = \", str(minIndex)\n",
    "min_value1 = tensor6[minIndex]\n",
    "minValue1Str = \"min value of tensor = \", str(min_value1)\n",
    "min_value2 = tf.reduce_min(tensor6)\n",
    "minValue2Str = \"min value using reduce_min = \", str(min_value2)\n",
    "\n",
    "tensor6, separator, maxIndexStr, maxValue1Str, maxValueStr2, separator, max_value1 == max_value2, separator, minIndexStr, minValue1Str, minValue2Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a0e4718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       " array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "            0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "            0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "            0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "            0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "            0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "            0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "            0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "            0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "            0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
       "       dtype=float32)>,\n",
       " '================',\n",
       " TensorShape([1, 1, 1, 1, 50]),\n",
       " '================',\n",
       " <tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       " array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "        0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "        0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "        0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "        0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "        0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "        0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "        0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "        0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "        0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "       dtype=float32)>,\n",
       " '================',\n",
       " TensorShape([50]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequeeze Tensor -- removing  all dimentsions of size one\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tensor7 = tf.constant(tf.random.uniform(shape=[50]), shape=(1,1,1,1,50))  \n",
    "squeezed = tf.squeeze(tensor7)                   \n",
    "tensor7, separator, tensor7.shape, separator, squeezed, separator, squeezed.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e911b027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The One Hot Encoding Matrix is  tf.Tensor(\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]], shape=(4, 5), dtype=float32)\n",
      "Other than numbers  tf.Tensor(\n",
      "[[b'On' b'off' b'off' b'off']\n",
      " [b'off' b'On' b'off' b'off']\n",
      " [b'off' b'off' b'On' b'off']\n",
      " [b'off' b'off' b'off' b'On']], shape=(4, 4), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encode Tensors\n",
    "# An Identity Matrix - where each 1 value is a different label.\n",
    "# Change the depth from 4 to 5 you get 5x4 array and there is no for the 5th row.\n",
    "some_list = [ 0, 1, 2, 3] # Labels are red = 0, green = 1, blue = 2, purple = 3\n",
    "print(\"The One Hot Encoding Matrix is \", tf.one_hot(some_list, depth = 5))\n",
    "print(\"Other than numbers \", tf.one_hot(some_list, depth=4, on_value=\"On\", off_value=\"off\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7938cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(9,), dtype=float32, numpy=array([ 1.,  4.,  9., 16., 25., 36., 49., 64., 81.], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       " array([0.99999994, 1.4142134 , 1.7320508 , 1.9999999 , 2.236068  ,\n",
       "        2.4494896 , 2.6457512 , 2.8284268 , 3.        ], dtype=float32)>,\n",
       " '================',\n",
       " <tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       " array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "        1.9459102, 2.0794415, 2.1972246], dtype=float32)>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying out more tensor math Operations\n",
    "# Trick \n",
    "tensor8 = tf.range(1.,10)\n",
    "tensor8, tf.square(tensor8), separator, tf.sqrt(tensor8), separator, tf.math.log(tensor8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae45fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is  (4, 2, 3)\n",
      "The number of dimensions is  3\n"
     ]
    }
   ],
   "source": [
    "# My first experiment :) -- find what ndim output should be \n",
    "\n",
    "test = tf.constant([[[1,2,3],[4,5,6]], [[7,8,9],[10,11,12]], [[7,8,9],[10,11,12]], [[7,8,9],[10,11,12]]])\n",
    "print(\"The shape is \", test.shape)\n",
    "print(\"The number of dimensions is \", test.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11488f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 1: Convert a tensor to numpy\n",
      "The type of test is  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "The type of numPyTest is  <class 'numpy.ndarray'>\n",
      "The type of a tensor create from an numppy data strcture is  <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Other functions\n",
    "# Create a tensor from numpy array the float 64 and from a python list or through tensor flow it is float 32 \n",
    "test\n",
    "numPyTest = test.numpy()\n",
    "numpyTensor = tf.constant(numPyTest)\n",
    "\n",
    "print(\"Function 1: Convert a tensor to numpy\")\n",
    "print(\"The type of test is \",type(test))\n",
    "print(\"The type of numPyTest is \", type(numPyTest))\n",
    "print(\"The type of a tensor create from an numppy data strcture is \", type(numpyTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dd17953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#BroadCasting\n",
    "\n",
    "# Under certain conditions smaller tensors are strectched automatically to fit larger tensors \n",
    "# when running combined operations on them.  Both space and time efficient as the broadcast \n",
    "# operation never materializes the expendnded tensors in memory.\n",
    "\n",
    "# Example -- Note were multiplying a size of (1,) and (1,3). The (1,) is change to a (1,3)\n",
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant(2)\n",
    "print(x*y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
